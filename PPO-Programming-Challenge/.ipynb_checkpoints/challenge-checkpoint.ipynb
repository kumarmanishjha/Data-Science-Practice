{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X', 'Y'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 502), (6000, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 5], dtype=int64), array([2000, 2000, 2000], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[Y > 1] = 2\n",
    "Y = Y.flatten()\n",
    "Y = pd.get_dummies(Y)\n",
    "Y =  Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ReLU, Tanh,Sigmoid\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#70% train, 20% validation, 10% test\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8897189 , 0.89118385, 0.8985018 , ..., 0.6807071 , 0.676409  ,\n",
       "        0.6761962 ],\n",
       "       [0.8698481 , 0.8754975 , 0.8797764 , ..., 0.6197327 , 0.61862373,\n",
       "        0.6150738 ],\n",
       "       [0.76998335, 0.77002126, 0.76289666, ..., 0.5952492 , 0.5978094 ,\n",
       "        0.595771  ],\n",
       "       [0.70036554, 0.6966747 , 0.6959275 , ..., 0.4321368 , 0.4293894 ,\n",
       "        0.42774132],\n",
       "       [0.6525331 , 0.6589684 , 0.6559166 , ..., 0.2711771 , 0.2698329 ,\n",
       "        0.2713656 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).long())\n",
    "val_data = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(Y_val).long())\n",
    "test_data = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_CLASS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size = BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer_1): Linear(in_features=502, out_features=512, bias=True)\n",
      "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Net(num_feature = X.shape[1], num_class=NUM_CLASS)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer_1): Linear(in_features=502, out_features=512, bias=True)\n",
      "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_acc(y_pred, y_true):\n",
    "    '''Returns prediction accuracy for a batch of output'''\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "\n",
    "    correct_pred = (y_pred_tags == y_true).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    acc = acc * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store accuracy and loss stats\n",
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                  | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████████████▍                                                                                                                                          | 1/10 [00:01<00:13,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.50413\n",
      "Val Loss: 0.62140\n",
      "Train Acc: 91.832\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████████████████████▊                                                                                                                           | 2/10 [00:01<00:08,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002: | Train Loss: 0.24582\n",
      "Val Loss: 0.26437\n",
      "Train Acc: 99.929\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████████████████████████████▏                                                                                                           | 3/10 [00:02<00:06,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003: | Train Loss: 0.16896\n",
      "Val Loss: 0.20115\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████████████████████████████████▌                                                                                            | 4/10 [00:02<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004: | Train Loss: 0.12687\n",
      "Val Loss: 0.13996\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████████████████████████████████████████                                                                             | 5/10 [00:02<00:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005: | Train Loss: 0.10034\n",
      "Val Loss: 0.10732\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 6/10 [00:02<00:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006: | Train Loss: 0.08203\n",
      "Val Loss: 0.09256\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 7/10 [00:03<00:01,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007: | Train Loss: 0.06803\n",
      "Val Loss: 0.06606\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 8/10 [00:03<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008: | Train Loss: 0.05649\n",
      "Val Loss: 0.06369\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 9/10 [00:03<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009: | Train Loss: 0.04887\n",
      "Val Loss: 0.05314\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010: | Train Loss: 0.04131\n",
      "Val Loss: 0.03894\n",
      "Train Acc: 100.000\n",
      "Val Acc: 190.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        X_train_batch, y_train_batch = data\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        labels = torch.max(y_train_batch, 1)[1]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_train_pred = model(X_train_batch)\n",
    "\n",
    "        train_loss = criterion(y_train_pred, labels)\n",
    "        train_acc = prediction_acc(y_train_pred, labels)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        #print(train_acc.item())\n",
    "\n",
    "\n",
    "    # Validation    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            labels = torch.max(y_val_batch, 1)[1]\n",
    "            \n",
    "            y_val_pred = model(X_val_batch)\n",
    "            #print(y_val_pred)\n",
    "                        \n",
    "            val_loss = criterion(y_val_pred, labels)\n",
    "            val_acc = prediction_acc(y_val_pred, labels)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "            #print(val_acc.item())\n",
    "            \n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(test_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(test_loader))\n",
    "                              \n",
    "    #print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f}' )\n",
    "    print(f'Val Loss: {val_epoch_loss/len(test_loader):.5f}' ) \n",
    "    print(f'Train Acc: {train_epoch_acc/len(train_loader):.3f}' )\n",
    "    print(f'Val Acc: {val_epoch_acc/len(test_loader):.3f}')\n",
    "    \n",
    "    \n",
    "MODEL_PATH = 'model.pth'\n",
    "torch.save(model, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_data):\n",
    "    '''Function to predict given test data'''\n",
    "    return predict_batch(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, test_batch):\n",
    "    '''Function to predict for a batch'''\n",
    "    Y_test = np.zeros((test_batch.shape[0],1)) #Dummy label to pass to dataloader\n",
    "    test_data = ClassifierDataset(torch.from_numpy(test_batch).float(), torch.from_numpy(Y_test).long())\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size = BATCH_SIZE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pred = []\n",
    "        for x_batch,_ in test_loader:\n",
    "            #x_test = x_batch.to(device)\n",
    "            x_test = x_batch.to('cpu')\n",
    "            y_test_pred = model(x_test)\n",
    "            y_test_pred = torch.log_softmax(y_test_pred, dim = 1)\n",
    "            _, prediction = torch.max(y_test_pred, dim = 1)\n",
    "            prediction = prediction.detach().cpu().numpy()\n",
    "            pred.append(prediction)\n",
    "            \n",
    "        pred= [i for sublist in pred for i in sublist]\n",
    "        \n",
    "\n",
    "    return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = predict_batch(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.argmax(Y_test, axis=-1) #True prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600,), (600,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 2, 2, 2, 1, 1, 1, 1], dtype=int64),\n",
       " array([2, 0, 2, 2, 2, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred[441:450],Y_test[441:450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.rand(1,502)\n",
    "predict(model, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 1, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.rand(10,502)\n",
    "predict(model, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time:  0.2619105999999647\n"
     ]
    }
   ],
   "source": [
    "## RUN TIME on GPU\n",
    "\n",
    "import timeit\n",
    "model_cpu = model.to(device)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "x1 = np.random.rand(10000,502)\n",
    "predict(model, x1)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Run Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time:  0.268890699999929\n"
     ]
    }
   ],
   "source": [
    "## RUN TIME on CPU\n",
    "\n",
    "import timeit\n",
    "\n",
    "model_cpu = model.to('cpu')\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "x1 = np.random.rand(10000,502)\n",
    "predict_batch(model_cpu, x1)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Run Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#70% train, 20% validation, 10% test\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(n_estimators=500,  bootstrap = True, min_samples_split=10)\n",
    "clf = RandomForestClassifier(n_estimators=500,  bootstrap = True, min_samples_split=10)\n",
    "# Fit on training data\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred=clf.predict(X_val)\n",
    "print(\"\\n\\n\\nRandom Forest Accuracy:\",accuracy_score(Y_val_pred, Y_val))\n",
    "print('Recall : ', recall_score(Y_val_pred, Y_val, average='macro'))\n",
    "print('Prescision : ', precision_score(Y_val_pred, Y_val, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred=clf.predict(X_test)\n",
    "print(\"\\n\\n\\nRandom Forest Accuracy:\",accuracy_score(Y_test_pred, Y_test))\n",
    "print('Recall : ', recall_score(Y_test_pred, Y_test, average='macro'))\n",
    "print('Prescision : ', precision_score(Y_test_pred, Y_test, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
